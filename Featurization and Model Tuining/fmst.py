# -*- coding: utf-8 -*-
"""FMST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mBWE1YiHne2Gxx12lSOtzQloua6eUlko

# FEATURIZATION AND MODEL TUNING PROJECT

******************************************************************************

**Data Description**

The actual concrete compressive strength(MPa) for a given mixture under a specific age (days) was determined from laboaratory. Data is in raw form(not scaled). The data has 8 quantitative input variables, and 1 quantitaive output variable and 1030 instances (observations)

**Domain**

Cement Manufacturing

**Context**

Concrete is the most important in civil enginerring, The concrete compressive strength is a highly non linear function of age and ingredients. These ingredients include cement, blast furnace slag, fly ash, water, superplasticizer, coarse aggregate, and fine aggreagate.

**Attribute** **Information**

* Cement           : measured in kg in a m3 mixture
* Blast            : measured in kg in a m3 mixture
* Fly ash          : measured in kg in a m3 mixture
* Water            : measured in kg in a m3 mixture
* Superplasticizer : measured in kg in a m3 mixture
* Coarse Aggregate : measured in kg in a m3 mixture
* Fine Agrregate   : measured in kg in a m3 mixture
* Age              : day (1~365)
* Concrete compressive strength measured in Mpa

**Objective**

Modeling of strength of high performance concrete using Machine Learning

* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *

importing the libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

"""importing the data"""

df = pd.read_csv('/content/concrete.csv')
df.head()

"""Summary of data"""

df.describe()

df.info()

"""*Conclusions that can be made out of it:*

* all the features given in the data are numeric
* There are no NULL or NaN values present in the data
* In total there are 8 features and 1030 observations
* We shall be using strength as the dependent variable and all other features as independent variable as it makes the best sense out of the problem objective.
* Age value ranges from 1 to 365

# UNIVARIATE ANALYSIS

**Description of all the Independent variables**

1. **Cement**
"""

print("Name of the attribute:", df.columns[0])
print("Range of values:", (df['cement'].max()-df['cement'].min()))
print("Mean value:", df['cement'].mean())
print("Median value:", df['cement'].median())
print("Standard deviation value:", df['cement'].std())
print("Quartiles values:")
print("1st Quartile", df['cement'].quantile(q=0.25))
print("3rd Quartile", df['cement'].quantile(q=0.75))

fig, (ax1,ax2,ax3)=plt.subplots(1,3,figsize=(13,5))
sns.set_palette('rainbow')

#boxplot
sns.boxplot(y='cement',data=df,orient='v',ax=ax1)
ax1.set_ylabel('Cement', fontsize=15)
ax1.set_title('Distribution of cement', fontsize=15)
ax1.tick_params(labelsize=15)

#distplot
sns.distplot(df['cement'],ax=ax2)
ax2.set_xlabel('Cement', fontsize=15)
ax2.set_ylabel('Strength', fontsize=15)
ax2.set_title('Cement vs Strength', fontsize=15)
ax2.tick_params(labelsize=15)

#histogram
sns.histplot(df['cement'])
ax3.set_xlabel('Cement', fontsize=15)
ax3.set_ylabel('Count', fontsize=15)
ax3.set_title('Cement Count', fontsize=15)
ax3.tick_params(labelsize=15)

plt.subplots_adjust(wspace=0.5)
plt.tight_layout()

"""2. **Slag**"""

print("Name of the attribute:", df.columns[1])
print("Range of values:", (df['slag'].max()-df['slag'].min()))
print("Mean value:", df['slag'].mean())
print("Median value:", df['slag'].median())
print("Standard deviation value:", df['slag'].std())
print("Quartiles values:")
print("1st Quartile", df['slag'].quantile(q=0.25))
print("3rd Quartile", df['slag'].quantile(q=0.75))

fig, (ax1,ax2,ax3)=plt.subplots(1,3,figsize=(13,5))

#boxplot
sns.boxplot(y='slag',data=df,orient='v',ax=ax1)
ax1.set_ylabel('Slag', fontsize=15)
ax1.set_title('Distribution of Slag', fontsize=15)
ax1.tick_params(labelsize=15)

#distplot
sns.distplot(df['slag'],ax=ax2)
ax2.set_xlabel('Slag', fontsize=15)
ax2.set_ylabel('Strength', fontsize=15)
ax2.set_title('Slag vs Strength', fontsize=15)
ax2.tick_params(labelsize=15)

#histogram
sns.histplot(x=df['slag'])
ax3.set_xlabel('Slag', fontsize=15)
ax3.set_ylabel('Count', fontsize=15)
ax3.set_title('Slag Count', fontsize=15)
ax3.tick_params(labelsize=15)

plt.subplots_adjust(wspace=0.5)
plt.tight_layout()

"""3. **Ash**"""

print("Name of the attribute:", df.columns[2])
print("Range of values:", (df['ash'].max()-df['ash'].min()))
print("Mean value:", df['ash'].mean())
print("Median value:", df['ash'].median())
print("Standard deviation value:", df['ash'].std())
print("Quartiles values:")
print("1st Quartile", df['ash'].quantile(q=0.25))
print("3rd Quartile", df['ash'].quantile(q=0.75))

fig, (ax1,ax2,ax3)=plt.subplots(1,3,figsize=(13,5))

#boxplot
sns.boxplot(y='ash',data=df,orient='v',ax=ax1)
ax1.set_ylabel('Ash', fontsize=15)
ax1.set_title('Distribution of Ash', fontsize=15)
ax1.tick_params(labelsize=15)

#distplot
sns.distplot(df['ash'],ax=ax2)
ax2.set_xlabel('Ash', fontsize=15)
ax2.set_ylabel('Strength', fontsize=15)
ax2.set_title('Ash vs Strength', fontsize=15)
ax2.tick_params(labelsize=15)

#histogram
sns.histplot(df['ash'])
ax3.set_xlabel('Cement', fontsize=15)
ax3.set_ylabel('Count', fontsize=15)
ax3.set_title('Ash Count', fontsize=15)
ax3.tick_params(labelsize=15)

plt.subplots_adjust(wspace=0.5)
plt.tight_layout()

"""4. **Water**"""

print("Name of the attribute:", df.columns[3])
print("Range of values:", (df['water'].max()-df['cement'].min()))
print("Mean value:", df['water'].mean())
print("Median value:", df['water'].median())
print("Standard deviation value:", df['water'].std())
print("Quartiles values:")
print("1st Quartile", df['water'].quantile(q=0.25))
print("3rd Quartile", df['water'].quantile(q=0.75))

fig, (ax1,ax2,ax3)=plt.subplots(1,3,figsize=(13,5))

#boxplot
sns.boxplot(y='water',data=df,orient='v',ax=ax1)
ax1.set_ylabel('Water', fontsize=15)
ax1.set_title('Distribution of water', fontsize=15)
ax1.tick_params(labelsize=15)

#distplot
sns.distplot(df['water'],ax=ax2)
ax2.set_xlabel('Cement', fontsize=15)
ax2.set_ylabel('Strength', fontsize=15)
ax2.set_title('Water vs Strength', fontsize=15)
ax2.tick_params(labelsize=15)

#histogram
sns.histplot(df['water'])
ax3.set_xlabel('water', fontsize=15)
ax3.set_ylabel('count', fontsize=15)
ax3.set_title('Water count', fontsize=15)
ax3.tick_params(labelsize=15)

plt.subplots_adjust(wspace=0.5)
plt.tight_layout()

"""5. **Superplastic**"""

print("Name of the attribute:", df.columns[4])
print("Range of values:", (df['superplastic'].max()-df['superplastic'].min()))
print("Mean value:", df['superplastic'].mean())
print("Median value:", df['superplastic'].median())
print("Standard deviation value:", df['superplastic'].std())
print("Quartiles values:")
print("1st Quartile", df['superplastic'].quantile(q=0.25))
print("3rd Quartile", df['superplastic'].quantile(q=0.75))

fig, (ax1,ax2,ax3)=plt.subplots(1,3,figsize=(13,5))

#boxplot
sns.boxplot(y='superplastic',data=df,orient='v',ax=ax1)
ax1.set_ylabel('superplastic', fontsize=15)
ax1.set_title('Distribution of superplastic', fontsize=15)
ax1.tick_params(labelsize=15)

#distplot
sns.distplot(df['superplastic'],ax=ax2)
ax2.set_xlabel('superplastic', fontsize=15)
ax2.set_ylabel('Strength', fontsize=15)
ax2.set_title('superplastic vs Strength', fontsize=15)
ax2.tick_params(labelsize=15)

#histogram
sns.histplot(df['superplastic'])
ax3.set_xlabel('superplastic', fontsize=15)
ax3.set_ylabel('count', fontsize=15)
ax3.set_title('superplastic count', fontsize=15)
ax3.tick_params(labelsize=15)

plt.subplots_adjust(wspace=0.5)
plt.tight_layout()

"""6. Coarseagg"""

print("Name of the attribute:", df.columns[5])
print("Range of values:", (df['coarseagg'].max()-df['coarseagg'].min()))
print("Mean value:", df['coarseagg'].mean())
print("Median value:", df['coarseagg'].median())
print("Standard deviation value:", df['coarseagg'].std())
print("Quartiles values:")
print("1st Quartile", df['coarseagg'].quantile(q=0.25))
print("3rd Quartile", df['coarseagg'].quantile(q=0.75))

fig, (ax1,ax2,ax3)=plt.subplots(1,3,figsize=(13,5))

#boxplot
sns.boxplot(y='coarseagg',data=df,orient='v',ax=ax1)
ax1.set_ylabel('Coarseagg', fontsize=15)
ax1.set_title('Distribution of coarseagg', fontsize=15)
ax1.tick_params(labelsize=15)

#distplot
sns.distplot(df['coarseagg'],ax=ax2)
ax2.set_xlabel('Coarseagg', fontsize=15)
ax2.set_ylabel('Strength', fontsize=15)
ax2.set_title('Coarseagg vs Strength', fontsize=15)
ax2.tick_params(labelsize=15)

#histogram
sns.histplot(df['coarseagg'])
ax3.set_xlabel('Coarseagg', fontsize=15)
ax3.set_ylabel('Count', fontsize=15)
ax3.set_title('Coarseagg count', fontsize=15)
ax3.tick_params(labelsize=15)

plt.subplots_adjust(wspace=0.5)
plt.tight_layout()

"""7. **Fineagg**"""

print("Name of the attribute:", df.columns[6])
print("Range of values:", (df['fineagg'].max()-df['fineagg'].min()))
print("Mean value:", df['fineagg'].mean())
print("Median value:", df['fineagg'].median())
print("Standard deviation value:", df['fineagg'].std())
print("Quartiles values:")
print("1st Quartile", df['fineagg'].quantile(q=0.25))
print("3rd Quartile", df['fineagg'].quantile(q=0.75))

fig, (ax1,ax2,ax3)=plt.subplots(1,3,figsize=(13,5))

#boxplot
sns.boxplot(y='fineagg',data=df,orient='v',ax=ax1)
ax1.set_ylabel('Fineagg', fontsize=15)
ax1.set_title('Distribution of Fineagg', fontsize=15)
ax1.tick_params(labelsize=15)

#distplot
sns.distplot(df['fineagg'],ax=ax2)
ax2.set_xlabel('Fineagg', fontsize=15)
ax2.set_ylabel('Strength', fontsize=15)
ax2.set_title('Fineagg vs Strength', fontsize=15)
ax2.tick_params(labelsize=15)

#histogram
sns.histplot(df['fineagg'])
ax3.set_xlabel('Fineagg', fontsize=15)
ax3.set_ylabel('Count', fontsize=15)
ax3.set_title('Fineagg count', fontsize=15)
ax3.tick_params(labelsize=15)

plt.subplots_adjust(wspace=0.5)
plt.tight_layout()

"""8. **Age**"""

print("Name of the attribute:", df.columns[7])
print("Range of values:", (df['age'].max()-df['age'].min()))
print("Mean value:", df['age'].mean())
print("Median value:", df['age'].median())
print("Standard deviation value:", df['age'].std())
print("Quartiles values:")
print("1st Quartile", df['age'].quantile(q=0.25))
print("3rd Quartile", df['age'].quantile(q=0.75))

fig, (ax1,ax2,ax3)=plt.subplots(1,3,figsize=(13,5))

#boxplot
sns.boxplot(y='age',data=df,orient='v',ax=ax1)
ax1.set_ylabel('Age', fontsize=15)
ax1.set_title('Distribution of Age', fontsize=15)
ax1.tick_params(labelsize=15)

#distplot
sns.distplot(df['age'],ax=ax2)
ax2.set_xlabel('Age', fontsize=15)
ax2.set_ylabel('Strength', fontsize=15)
ax2.set_title('Age vs Strength', fontsize=15)
ax2.tick_params(labelsize=15)

#histogram
sns.histplot(df['age'])
ax3.set_xlabel('Age', fontsize=15)
ax3.set_ylabel('Count', fontsize=15)
ax3.set_title('Age count', fontsize=15)
ax3.tick_params(labelsize=15)

plt.subplots_adjust(wspace=0.5)
plt.tight_layout()

"""# MULTIVARIATE ANALYSIS"""

sns.pairplot(df, diag_kind= 'kde', palette='Pastel2')

fig, ax2 = plt.subplots(3, 3, figsize=(16, 16))
sns.set_palette('Pastel2')
sns.histplot(df['cement'],ax=ax2[0][0])
sns.histplot(df['slag'],ax=ax2[0][1])
sns.histplot(df['ash'],ax=ax2[0][2])
sns.histplot(df['water'],ax=ax2[1][0])
sns.histplot(df['superplastic'],ax=ax2[1][1])
sns.histplot(df['coarseagg'],ax=ax2[1][2])
sns.histplot(df['fineagg'],ax=ax2[2][0])
sns.histplot(df['age'],ax=ax2[2][1])
sns.histplot(df['strength'],ax=ax2[2][2])

"""*Conclusion that can be drawn from bi-variate analysis:*

* cement and strength are the 2 attributes which looks more normal than other attributes
* slag, ash, superplastic, age are the attributes which are rightly skewed.
* Except cement and strength all other attributes have multiple/ more than one Gaussians.

* from the joint plots we can plotted and individual attribute's boxplots which were plotted before are the evidences that there are outliers present in the attributes: slag, ash, superplastic, fineagg, age

* The above heatmap shows that there aren't any missing values in the data.
* So no furhter imputations are needed as there aren't any missing values.
"""

sns.heatmap(df.isna(), yticklabels= False, cbar= False, cmap = 'viridis')

"""*Relationship between the dependent and independent variables:*"""

df.corr()

plt.figure(figsize=(10,6))
sns.heatmap(df.corr(), annot= True, cmap='BuPu', linecolor='black')
plt.title("Correlation between the variables")

"""* Strength vs Cement: is highly positively correlated, it's also linearly related
* Strength vs Slag: is positively correalted with less degree of correaltion
* Strength vs Ash: is negatively correlated of almost -0.2
* Strength vs Water:- Negatively correalted and poorly realted to dependent variable
* Strength vs Superplastic: positive and fairly correalted of almost 0.4
* Strength vs coarseagg/fineagg : negatively correalted
* Strength vs age: positively and fairly correalted

# FETURE ENGINEERING, BUIDING MODELS AND MODEL TUNING

Scaling the varaibles in the data
"""

df.columns

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(df[['cement', 'slag', 'ash', 'water', 'superplastic', 'coarseagg','fineagg', 'age', 'strength']])

scaled_df = scaler.transform(df[['cement', 'slag', 'ash', 'water', 'superplastic', 'coarseagg','fineagg', 'age', 'strength']])
scaled_df[:5]

df_new = pd.DataFrame(scaled_df, columns= df.columns)
df_new.head()

"""Split the data"""

X = df_new[['cement', 'slag', 'ash', 'water', 'superplastic', 'coarseagg','fineagg', 'age']]
y = df_new['strength']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=1)

X_train[:5]

y_train[:5]

"""**Algorithm**:- *Linear Regression*"""

from sklearn.linear_model import LinearRegression
linear_reg = LinearRegression() #initialize
linear_reg.fit(X_train, y_train) # training the model
linear_reg_pred = linear_reg.predict(X_test)

from sklearn import metrics
linear_reg_r2 = metrics.r2_score(y_test, linear_reg_pred)
print("R^2 Score:", linear_reg_r2)
print("Mean Squared Error:", metrics.mean_squared_error(y_test, linear_reg_pred))

"""**Algorithm**:- *Decision Tree Regressor*"""

from sklearn.tree import DecisionTreeRegressor
decision_reg = DecisionTreeRegressor()  #intialize
decision_reg.fit(X_train, y_train)  # training
decision_reg_pred = decision_reg.predict(X_test)

decision_reg_r2 = metrics.r2_score(y_test, decision_reg_pred)
print("R^2 Score:", decision_reg_r2)
print("Mean Squared Error:", metrics.mean_squared_error(y_test, decision_reg_pred))

"""**Algorithm**:- *Random Forest Regressor*"""

from sklearn.ensemble import RandomForestRegressor
random_reg = RandomForestRegressor()  #intialize
random_reg.fit(X_train, y_train)  # training
random_reg_pred = random_reg.predict(X_test)

random_reg_r2 = metrics.r2_score(y_test, random_reg_pred)
print("R^2 Score:", random_reg_r2)
print("Mean Squared Error:", metrics.mean_squared_error(y_test, random_reg_pred))

"""**Algorithm**:- *Stochastic Gradient Descent Regressor*"""

from sklearn.linear_model import SGDRegressor
sgd_reg = SGDRegressor()  #intialize
sgd_reg.fit(X_train, y_train)  # training
sgd_reg_pred = sgd_reg.predict(X_test)

sgd_reg_r2 = metrics.r2_score(y_test, sgd_reg_pred)
print("R^2 Score:", sgd_reg_r2)
print("Mean Squared Error:", metrics.mean_squared_error(y_test, sgd_reg_pred))

"""**Algorithm**:- *Gradient Boosting Regressor*"""

from sklearn.ensemble import GradientBoostingRegressor
gradient_boost_reg = GradientBoostingRegressor()  # intialize
gradient_boost_reg.fit(X_train, y_train)  # training
gradient_boost_reg_pred = gradient_boost_reg.predict(X_test)

gradient_boost_reg_r2 = metrics.r2_score(y_test, gradient_boost_reg_pred)
print("R^2 Score:", gradient_boost_reg_r2)
print("Mean Squared Error:", metrics.mean_squared_error(y_test, gradient_boost_reg_pred))

"""Hyper Parameter Tuning of Random Forest Regressor"""

from sklearn.model_selection import GridSearchCV
params = {'n_estimators':[50,100,150,200], 'criterion':['mse','mae'], 'max_depth':[None, 10,20,30,100], 'bootstrap':[True, False]}
grid_model = GridSearchCV(RandomForestRegressor(), params, verbose=3, )

grid_model.fit(X_train, y_train)

grid_model.best_params_

random_reg_grid = RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=30, n_estimators=50)  #intialize
random_reg_grid.fit(X_train, y_train)  # training
random_reg_grid_pred = random_reg_grid.predict(X_test)

random_reg_grid_r2 = metrics.r2_score(y_test, random_reg_grid_pred)
print("R^2 Score:", random_reg_grid_r2)
print("Mean Squared Error:", metrics.mean_squared_error(y_test, random_reg_grid_pred))

"""MODEL ACCURACIES"""

accuracy = pd.DataFrame({'Method':['Linear regression','Decision Tree Regressor','Random Forest Regressor', 'Stochastic Gradient Descent Regressor', 'Gradient Boosting Regressor', 'Hyper Parameter tuned Random Forest Regressor'],
                         'R^2 Scores':[linear_reg_r2, decision_reg_r2, random_reg_r2, sgd_reg_r2, gradient_boost_reg_r2,random_reg_grid_r2]})
accuracy

"""From the table above we conclude that:
* Random Forest Regressor, Gradient Boosting Regressor and hyper parameter tuned Random Forest Regressor have the highest r2 scores as comapred to other algorithms like Linear Regression, Decision Tree Regressor, Stochastic Gradient Descent
"""